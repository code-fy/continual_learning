{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f99b0ab",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47a14703",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-2483ac3f0dd9>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "mnist = input_data.read_data_sets(\"./MNIST_data\",one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97f08f",
   "metadata": {},
   "source": [
    "使用estimator自定义lenet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d087765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet(x,is_training):\n",
    "    x = tf.reshape(x,shape=[-1,28,28,1])\n",
    "    net =tf.layers.conv2d(x,32,5,activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling2d(net,2,2)\n",
    "    net = tf.layers.conv2d(net,64,3,activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling2d(net,2,2)\n",
    "    net = tf.contrib.layers.flatten(net)\n",
    "    net = tf.layers.dense(net,1024)\n",
    "    net = tf.layers.dropout(net,rate=0.4,training=is_training)\n",
    "    return tf.layers.dense(net,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f33d7",
   "metadata": {},
   "source": [
    "#### 自定义estimator中使用的模型，定义的函数有4个输入：\n",
    "features给出了在输入函数中会提供的输入层张量，注意这是一个字典，\n",
    "字典里的内容是通过tf.estimator.inputs.numpy_input_fn中x参数指定，\n",
    "labels是正确答案，这个字段内容通过numpy_input_fn中的y参数给出。\n",
    "mode的去只有三种可能，分别对应train，eval，predict。\n",
    "params是一个字典，存放模型相关的任意超参数，eg：lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2a6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features,labels,mode,params):\n",
    "    predict = lenet(\n",
    "        features[\"image\"],mode == tf.estimator.ModeKeys.TRAIN\n",
    "    )\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions={\"result\":tf.argmax(predict,1)}\n",
    "        )\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=predict,labels=labels))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=params[\"learning_rate\"])\n",
    "    train_op = optimizer.minimize(\n",
    "        loss = loss,global_step=tf.train.get_global_step()\n",
    "    )\n",
    "    eval_metric_ops = {\n",
    "        \"my_metric\":tf.metrics.accuracy(\n",
    "            tf.argmax(predict,1),labels\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        loss = loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eae53e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"learning_rate\":0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c8b1ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './udf_log', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe78c61af60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn=model_fn,params=model_params,model_dir = \"./udf_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2278d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"image\":mnist.train.images},\n",
    "    y=mnist.train.labels.astype(np.int32),\n",
    "    num_epochs=None,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1dfe100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-3-28a206a33e0a>:3: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78c0ecef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78c0ecef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-3-28a206a33e0a>:4: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78c0ecef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78c0ecef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78c0ecef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78c0ecef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78c0ecef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78c0ecef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe78b3a4dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe78b3a4dd8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe78b3a4dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe78b3a4dd8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From <ipython-input-3-28a206a33e0a>:8: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78c0ecef0>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78c0ecef0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From <ipython-input-3-28a206a33e0a>:9: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe78c0ecef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe78c0ecef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78c0ecef0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78c0ecef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78c0ecef0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./udf_log/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3241022, step = 1\n",
      "INFO:tensorflow:global_step/sec: 18.9932\n",
      "INFO:tensorflow:loss = 1.7296016, step = 101 (5.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3703\n",
      "INFO:tensorflow:loss = 0.676988, step = 201 (4.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.289\n",
      "INFO:tensorflow:loss = 0.49471512, step = 301 (4.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0317\n",
      "INFO:tensorflow:loss = 0.40507102, step = 401 (4.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1733\n",
      "INFO:tensorflow:loss = 0.31840688, step = 501 (4.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.708\n",
      "INFO:tensorflow:loss = 0.26170263, step = 601 (5.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1817\n",
      "INFO:tensorflow:loss = 0.27306738, step = 701 (4.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1545\n",
      "INFO:tensorflow:loss = 0.20736195, step = 801 (4.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.9802\n",
      "INFO:tensorflow:loss = 0.15747577, step = 901 (5.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.9124\n",
      "INFO:tensorflow:loss = 0.2262969, step = 1001 (5.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3642\n",
      "INFO:tensorflow:loss = 0.105041325, step = 1101 (4.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1397\n",
      "INFO:tensorflow:loss = 0.24364212, step = 1201 (4.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4866\n",
      "INFO:tensorflow:loss = 0.2660649, step = 1301 (5.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6916\n",
      "INFO:tensorflow:loss = 0.14413857, step = 1401 (5.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2822\n",
      "INFO:tensorflow:loss = 0.1874753, step = 1501 (5.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.022\n",
      "INFO:tensorflow:loss = 0.14488272, step = 1601 (4.994 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3368\n",
      "INFO:tensorflow:loss = 0.1729461, step = 1701 (4.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1325\n",
      "INFO:tensorflow:loss = 0.12008814, step = 1801 (4.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8583\n",
      "INFO:tensorflow:loss = 0.14464578, step = 1901 (5.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2116\n",
      "INFO:tensorflow:loss = 0.13433087, step = 2001 (4.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1693\n",
      "INFO:tensorflow:loss = 0.0683344, step = 2101 (4.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.928\n",
      "INFO:tensorflow:loss = 0.16069032, step = 2201 (5.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1924\n",
      "INFO:tensorflow:loss = 0.19385484, step = 2301 (4.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.164\n",
      "INFO:tensorflow:loss = 0.22059502, step = 2401 (4.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.9299\n",
      "INFO:tensorflow:loss = 0.1479544, step = 2501 (5.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2414\n",
      "INFO:tensorflow:loss = 0.13163015, step = 2601 (4.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.294\n",
      "INFO:tensorflow:loss = 0.09671536, step = 2701 (4.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2719\n",
      "INFO:tensorflow:loss = 0.11988909, step = 2801 (4.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.257\n",
      "INFO:tensorflow:loss = 0.07377869, step = 2901 (4.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2646\n",
      "INFO:tensorflow:loss = 0.068109795, step = 3001 (4.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6947\n",
      "INFO:tensorflow:loss = 0.084581986, step = 3101 (5.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1192\n",
      "INFO:tensorflow:loss = 0.12533538, step = 3201 (4.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3159\n",
      "INFO:tensorflow:loss = 0.07438932, step = 3301 (4.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3293\n",
      "INFO:tensorflow:loss = 0.08560233, step = 3401 (4.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0614\n",
      "INFO:tensorflow:loss = 0.18574038, step = 3501 (4.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3739\n",
      "INFO:tensorflow:loss = 0.08708179, step = 3601 (4.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3169\n",
      "INFO:tensorflow:loss = 0.111423835, step = 3701 (4.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.246\n",
      "INFO:tensorflow:loss = 0.069167, step = 3801 (4.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2491\n",
      "INFO:tensorflow:loss = 0.09586494, step = 3901 (4.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.252\n",
      "INFO:tensorflow:loss = 0.11248852, step = 4001 (4.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2458\n",
      "INFO:tensorflow:loss = 0.07504375, step = 4101 (4.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.225\n",
      "INFO:tensorflow:loss = 0.047923874, step = 4201 (4.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2584\n",
      "INFO:tensorflow:loss = 0.067701474, step = 4301 (4.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0547\n",
      "INFO:tensorflow:loss = 0.058803435, step = 4401 (4.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0818\n",
      "INFO:tensorflow:loss = 0.112991385, step = 4501 (4.980 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 20.2497\n",
      "INFO:tensorflow:loss = 0.14714053, step = 4601 (4.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1729\n",
      "INFO:tensorflow:loss = 0.069345266, step = 4701 (4.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7504\n",
      "INFO:tensorflow:loss = 0.09245147, step = 4801 (5.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2458\n",
      "INFO:tensorflow:loss = 0.14516214, step = 4901 (4.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.9145\n",
      "INFO:tensorflow:loss = 0.03937383, step = 5001 (5.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2138\n",
      "INFO:tensorflow:loss = 0.1473541, step = 5101 (4.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.9801\n",
      "INFO:tensorflow:loss = 0.077535704, step = 5201 (5.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2362\n",
      "INFO:tensorflow:loss = 0.038369354, step = 5301 (4.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8051\n",
      "INFO:tensorflow:loss = 0.021827865, step = 5401 (5.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1445\n",
      "INFO:tensorflow:loss = 0.098043755, step = 5501 (4.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8752\n",
      "INFO:tensorflow:loss = 0.06274233, step = 5601 (5.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.1521\n",
      "INFO:tensorflow:loss = 0.07203831, step = 5701 (4.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7718\n",
      "INFO:tensorflow:loss = 0.1160894, step = 5801 (5.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9141\n",
      "INFO:tensorflow:loss = 0.077321626, step = 5901 (5.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4965\n",
      "INFO:tensorflow:loss = 0.06716549, step = 6001 (5.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9987\n",
      "INFO:tensorflow:loss = 0.018142186, step = 6101 (5.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.6032\n",
      "INFO:tensorflow:loss = 0.0955744, step = 6201 (5.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7201\n",
      "INFO:tensorflow:loss = 0.100395665, step = 6301 (5.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3668\n",
      "INFO:tensorflow:loss = 0.09120112, step = 6401 (5.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6797\n",
      "INFO:tensorflow:loss = 0.07537297, step = 6501 (5.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1798\n",
      "INFO:tensorflow:loss = 0.10993746, step = 6601 (5.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7959\n",
      "INFO:tensorflow:loss = 0.087280475, step = 6701 (5.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8812\n",
      "INFO:tensorflow:loss = 0.058949254, step = 6801 (5.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2279\n",
      "INFO:tensorflow:loss = 0.17277084, step = 6901 (5.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8275\n",
      "INFO:tensorflow:loss = 0.086882286, step = 7001 (5.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.761\n",
      "INFO:tensorflow:loss = 0.05180876, step = 7101 (5.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7507\n",
      "INFO:tensorflow:loss = 0.044300772, step = 7201 (5.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4791\n",
      "INFO:tensorflow:loss = 0.045226738, step = 7301 (5.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2435\n",
      "INFO:tensorflow:loss = 0.06661464, step = 7401 (5.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4736\n",
      "INFO:tensorflow:loss = 0.06402485, step = 7501 (5.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6143\n",
      "INFO:tensorflow:loss = 0.04489102, step = 7601 (5.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3939\n",
      "INFO:tensorflow:loss = 0.06336193, step = 7701 (5.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4213\n",
      "INFO:tensorflow:loss = 0.055747174, step = 7801 (5.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6649\n",
      "INFO:tensorflow:loss = 0.025829617, step = 7901 (5.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7359\n",
      "INFO:tensorflow:loss = 0.06510314, step = 8001 (5.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6399\n",
      "INFO:tensorflow:loss = 0.11674605, step = 8101 (5.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2337\n",
      "INFO:tensorflow:loss = 0.11763972, step = 8201 (5.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3254\n",
      "INFO:tensorflow:loss = 0.11510129, step = 8301 (5.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3233\n",
      "INFO:tensorflow:loss = 0.08128868, step = 8401 (5.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.726\n",
      "INFO:tensorflow:loss = 0.025311386, step = 8501 (5.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8446\n",
      "INFO:tensorflow:loss = 0.05394764, step = 8601 (5.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5695\n",
      "INFO:tensorflow:loss = 0.08035375, step = 8701 (5.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.329\n",
      "INFO:tensorflow:loss = 0.045719866, step = 8801 (5.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3721\n",
      "INFO:tensorflow:loss = 0.01864398, step = 8901 (5.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8521\n",
      "INFO:tensorflow:loss = 0.06595805, step = 9001 (5.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8066\n",
      "INFO:tensorflow:loss = 0.05284556, step = 9101 (5.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7362\n",
      "INFO:tensorflow:loss = 0.06088754, step = 9201 (5.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7893\n",
      "INFO:tensorflow:loss = 0.019657087, step = 9301 (5.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6728\n",
      "INFO:tensorflow:loss = 0.026327591, step = 9401 (5.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2833\n",
      "INFO:tensorflow:loss = 0.049023677, step = 9501 (5.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.412\n",
      "INFO:tensorflow:loss = 0.037250593, step = 9601 (5.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8227\n",
      "INFO:tensorflow:loss = 0.01677685, step = 9701 (5.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8455\n",
      "INFO:tensorflow:loss = 0.045518078, step = 9801 (5.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8039\n",
      "INFO:tensorflow:loss = 0.016809454, step = 9901 (5.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8121\n",
      "INFO:tensorflow:loss = 0.09036408, step = 10001 (5.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4484\n",
      "INFO:tensorflow:loss = 0.06783724, step = 10101 (5.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3337\n",
      "INFO:tensorflow:loss = 0.052812945, step = 10201 (5.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.368\n",
      "INFO:tensorflow:loss = 0.013737501, step = 10301 (5.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8207\n",
      "INFO:tensorflow:loss = 0.03131544, step = 10401 (5.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8074\n",
      "INFO:tensorflow:loss = 0.025182646, step = 10501 (5.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5227\n",
      "INFO:tensorflow:loss = 0.1402427, step = 10601 (5.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7479\n",
      "INFO:tensorflow:loss = 0.024560917, step = 10701 (5.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9164\n",
      "INFO:tensorflow:loss = 0.028811306, step = 10801 (5.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9916\n",
      "INFO:tensorflow:loss = 0.13000277, step = 10901 (5.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9773\n",
      "INFO:tensorflow:loss = 0.018326443, step = 11001 (5.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9633\n",
      "INFO:tensorflow:loss = 0.083041824, step = 11101 (5.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.02\n",
      "INFO:tensorflow:loss = 0.08938553, step = 11201 (5.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3133\n",
      "INFO:tensorflow:loss = 0.008907097, step = 11301 (5.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2502\n",
      "INFO:tensorflow:loss = 0.061706096, step = 11401 (5.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2825\n",
      "INFO:tensorflow:loss = 0.06457772, step = 11501 (5.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2693\n",
      "INFO:tensorflow:loss = 0.09280392, step = 11601 (5.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.0654\n",
      "INFO:tensorflow:loss = 0.078186646, step = 11701 (5.245 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11708 into ./udf_log/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 18.6933\n",
      "INFO:tensorflow:loss = 0.028091006, step = 11801 (5.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7993\n",
      "INFO:tensorflow:loss = 0.048303716, step = 11901 (5.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7775\n",
      "INFO:tensorflow:loss = 0.04916392, step = 12001 (5.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3489\n",
      "INFO:tensorflow:loss = 0.034067947, step = 12101 (5.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3087\n",
      "INFO:tensorflow:loss = 0.044417623, step = 12201 (5.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2712\n",
      "INFO:tensorflow:loss = 0.023468208, step = 12301 (5.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2643\n",
      "INFO:tensorflow:loss = 0.024033602, step = 12401 (5.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6078\n",
      "INFO:tensorflow:loss = 0.049293466, step = 12501 (5.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7822\n",
      "INFO:tensorflow:loss = 0.08154124, step = 12601 (5.055 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 19.6764\n",
      "INFO:tensorflow:loss = 0.13373329, step = 12701 (5.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3018\n",
      "INFO:tensorflow:loss = 0.022661239, step = 12801 (5.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2993\n",
      "INFO:tensorflow:loss = 0.03457316, step = 12901 (5.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3346\n",
      "INFO:tensorflow:loss = 0.052166916, step = 13001 (5.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4369\n",
      "INFO:tensorflow:loss = 0.022655964, step = 13101 (5.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8365\n",
      "INFO:tensorflow:loss = 0.17919725, step = 13201 (5.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7777\n",
      "INFO:tensorflow:loss = 0.03837707, step = 13301 (5.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3575\n",
      "INFO:tensorflow:loss = 0.05598544, step = 13401 (5.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1845\n",
      "INFO:tensorflow:loss = 0.045968078, step = 13501 (5.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3103\n",
      "INFO:tensorflow:loss = 0.027033634, step = 13601 (5.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3168\n",
      "INFO:tensorflow:loss = 0.03175223, step = 13701 (5.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3019\n",
      "INFO:tensorflow:loss = 0.053186227, step = 13801 (5.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5117\n",
      "INFO:tensorflow:loss = 0.03347685, step = 13901 (5.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7993\n",
      "INFO:tensorflow:loss = 0.015859468, step = 14001 (5.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6941\n",
      "INFO:tensorflow:loss = 0.040376004, step = 14101 (5.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3131\n",
      "INFO:tensorflow:loss = 0.00686477, step = 14201 (5.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3286\n",
      "INFO:tensorflow:loss = 0.02830098, step = 14301 (5.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3539\n",
      "INFO:tensorflow:loss = 0.044398867, step = 14401 (5.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.0805\n",
      "INFO:tensorflow:loss = 0.030394588, step = 14501 (5.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3608\n",
      "INFO:tensorflow:loss = 0.014198288, step = 14601 (5.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.105\n",
      "INFO:tensorflow:loss = 0.024382804, step = 14701 (4.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4727\n",
      "INFO:tensorflow:loss = 0.01590235, step = 14801 (5.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2866\n",
      "INFO:tensorflow:loss = 0.014791902, step = 14901 (5.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3155\n",
      "INFO:tensorflow:loss = 0.02166893, step = 15001 (5.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3271\n",
      "INFO:tensorflow:loss = 0.036606696, step = 15101 (5.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3115\n",
      "INFO:tensorflow:loss = 0.04315806, step = 15201 (5.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3291\n",
      "INFO:tensorflow:loss = 0.003072297, step = 15301 (5.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2989\n",
      "INFO:tensorflow:loss = 0.039302323, step = 15401 (5.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.0635\n",
      "INFO:tensorflow:loss = 0.09610145, step = 15501 (5.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5204\n",
      "INFO:tensorflow:loss = 0.01902194, step = 15601 (5.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6773\n",
      "INFO:tensorflow:loss = 0.06867257, step = 15701 (5.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.384\n",
      "INFO:tensorflow:loss = 0.014010495, step = 15801 (5.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.301\n",
      "INFO:tensorflow:loss = 0.020447183, step = 15901 (5.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3869\n",
      "INFO:tensorflow:loss = 0.022798639, step = 16001 (5.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1521\n",
      "INFO:tensorflow:loss = 0.009083396, step = 16101 (5.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8843\n",
      "INFO:tensorflow:loss = 0.021965679, step = 16201 (5.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2375\n",
      "INFO:tensorflow:loss = 0.058962382, step = 16301 (5.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4612\n",
      "INFO:tensorflow:loss = 0.04392491, step = 16401 (5.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7685\n",
      "INFO:tensorflow:loss = 0.0350752, step = 16501 (5.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4498\n",
      "INFO:tensorflow:loss = 0.011098402, step = 16601 (5.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.9971\n",
      "INFO:tensorflow:loss = 0.07839449, step = 16701 (5.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.9687\n",
      "INFO:tensorflow:loss = 0.02900219, step = 16801 (5.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.307\n",
      "INFO:tensorflow:loss = 0.05668606, step = 16901 (5.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2793\n",
      "INFO:tensorflow:loss = 0.035704635, step = 17001 (5.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.7375\n",
      "INFO:tensorflow:loss = 0.04099452, step = 17101 (5.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.5904\n",
      "INFO:tensorflow:loss = 0.015100025, step = 17201 (5.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2766\n",
      "INFO:tensorflow:loss = 0.008171214, step = 17301 (5.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7813\n",
      "INFO:tensorflow:loss = 0.023709126, step = 17401 (5.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7905\n",
      "INFO:tensorflow:loss = 0.05468912, step = 17501 (5.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.866\n",
      "INFO:tensorflow:loss = 0.013044001, step = 17601 (5.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.0979\n",
      "INFO:tensorflow:loss = 0.03536047, step = 17701 (5.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3345\n",
      "INFO:tensorflow:loss = 0.0072566336, step = 17801 (5.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0302\n",
      "INFO:tensorflow:loss = 0.061856113, step = 17901 (4.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4079\n",
      "INFO:tensorflow:loss = 0.028083503, step = 18001 (5.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3551\n",
      "INFO:tensorflow:loss = 0.044507273, step = 18101 (5.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3413\n",
      "INFO:tensorflow:loss = 0.051725, step = 18201 (5.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3327\n",
      "INFO:tensorflow:loss = 0.0146857295, step = 18301 (5.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2451\n",
      "INFO:tensorflow:loss = 0.05301537, step = 18401 (5.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3785\n",
      "INFO:tensorflow:loss = 0.13007769, step = 18501 (5.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.359\n",
      "INFO:tensorflow:loss = 0.0037717395, step = 18601 (5.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3169\n",
      "INFO:tensorflow:loss = 0.005664152, step = 18701 (5.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3377\n",
      "INFO:tensorflow:loss = 0.028161213, step = 18801 (5.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6822\n",
      "INFO:tensorflow:loss = 0.026252497, step = 18901 (5.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8155\n",
      "INFO:tensorflow:loss = 0.007623546, step = 19001 (5.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4265\n",
      "INFO:tensorflow:loss = 0.027705928, step = 19101 (5.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.358\n",
      "INFO:tensorflow:loss = 0.019758167, step = 19201 (5.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2719\n",
      "INFO:tensorflow:loss = 0.08022916, step = 19301 (5.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3019\n",
      "INFO:tensorflow:loss = 0.029584419, step = 19401 (5.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3142\n",
      "INFO:tensorflow:loss = 0.27625027, step = 19501 (5.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3496\n",
      "INFO:tensorflow:loss = 0.030850995, step = 19601 (5.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3327\n",
      "INFO:tensorflow:loss = 0.030081535, step = 19701 (5.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3609\n",
      "INFO:tensorflow:loss = 0.0067882417, step = 19801 (5.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8098\n",
      "INFO:tensorflow:loss = 0.024366304, step = 19901 (5.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.724\n",
      "INFO:tensorflow:loss = 0.026674394, step = 20001 (5.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3646\n",
      "INFO:tensorflow:loss = 0.013043679, step = 20101 (5.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2566\n",
      "INFO:tensorflow:loss = 0.10367651, step = 20201 (5.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.306\n",
      "INFO:tensorflow:loss = 0.05261617, step = 20301 (5.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3372\n",
      "INFO:tensorflow:loss = 0.05342293, step = 20401 (5.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3141\n",
      "INFO:tensorflow:loss = 0.024768915, step = 20501 (5.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3031\n",
      "INFO:tensorflow:loss = 0.02364038, step = 20601 (5.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3385\n",
      "INFO:tensorflow:loss = 0.012646031, step = 20701 (5.171 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 18.8307\n",
      "INFO:tensorflow:loss = 0.051864725, step = 20801 (5.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2815\n",
      "INFO:tensorflow:loss = 0.019904729, step = 20901 (5.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3111\n",
      "INFO:tensorflow:loss = 0.02684717, step = 21001 (5.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3097\n",
      "INFO:tensorflow:loss = 0.031701762, step = 21101 (5.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3428\n",
      "INFO:tensorflow:loss = 0.023589652, step = 21201 (5.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3191\n",
      "INFO:tensorflow:loss = 0.014757856, step = 21301 (5.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.866\n",
      "INFO:tensorflow:loss = 0.01553615, step = 21401 (5.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1707\n",
      "INFO:tensorflow:loss = 0.07221767, step = 21501 (5.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3123\n",
      "INFO:tensorflow:loss = 0.027856361, step = 21601 (5.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2918\n",
      "INFO:tensorflow:loss = 0.023570567, step = 21701 (5.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.242\n",
      "INFO:tensorflow:loss = 0.04358625, step = 21801 (5.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3332\n",
      "INFO:tensorflow:loss = 0.061832257, step = 21901 (5.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2949\n",
      "INFO:tensorflow:loss = 0.038596988, step = 22001 (5.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2445\n",
      "INFO:tensorflow:loss = 0.021518778, step = 22101 (5.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3005\n",
      "INFO:tensorflow:loss = 0.019905344, step = 22201 (5.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4241\n",
      "INFO:tensorflow:loss = 0.09009801, step = 22301 (5.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.326\n",
      "INFO:tensorflow:loss = 0.029460683, step = 22401 (5.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3264\n",
      "INFO:tensorflow:loss = 0.015830176, step = 22501 (5.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3432\n",
      "INFO:tensorflow:loss = 0.041771382, step = 22601 (5.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7896\n",
      "INFO:tensorflow:loss = 0.016520167, step = 22701 (5.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7293\n",
      "INFO:tensorflow:loss = 0.06709694, step = 22801 (5.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2883\n",
      "INFO:tensorflow:loss = 0.006779316, step = 22901 (5.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2299\n",
      "INFO:tensorflow:loss = 0.027451968, step = 23001 (5.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.9902\n",
      "INFO:tensorflow:loss = 0.033018984, step = 23101 (5.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5518\n",
      "INFO:tensorflow:loss = 0.010243433, step = 23201 (5.697 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23293 into ./udf_log/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 17.3141\n",
      "INFO:tensorflow:loss = 0.040175572, step = 23301 (5.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2613\n",
      "INFO:tensorflow:loss = 0.012698343, step = 23401 (5.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7793\n",
      "INFO:tensorflow:loss = 0.024102785, step = 23501 (5.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4072\n",
      "INFO:tensorflow:loss = 0.00940709, step = 23601 (5.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2978\n",
      "INFO:tensorflow:loss = 0.0038843965, step = 23701 (5.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5028\n",
      "INFO:tensorflow:loss = 0.06789274, step = 23801 (5.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.0493\n",
      "INFO:tensorflow:loss = 0.0034412052, step = 23901 (5.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.39\n",
      "INFO:tensorflow:loss = 0.0145086795, step = 24001 (5.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.342\n",
      "INFO:tensorflow:loss = 0.009689125, step = 24101 (5.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3379\n",
      "INFO:tensorflow:loss = 0.03328215, step = 24201 (5.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2991\n",
      "INFO:tensorflow:loss = 0.01512695, step = 24301 (5.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.33\n",
      "INFO:tensorflow:loss = 0.051564008, step = 24401 (5.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1361\n",
      "INFO:tensorflow:loss = 0.06521051, step = 24501 (5.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3489\n",
      "INFO:tensorflow:loss = 0.024556162, step = 24601 (5.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3299\n",
      "INFO:tensorflow:loss = 0.036380164, step = 24701 (5.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3424\n",
      "INFO:tensorflow:loss = 0.023049865, step = 24801 (5.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3154\n",
      "INFO:tensorflow:loss = 0.002711385, step = 24901 (5.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3737\n",
      "INFO:tensorflow:loss = 0.046338834, step = 25001 (5.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8924\n",
      "INFO:tensorflow:loss = 0.020400826, step = 25101 (5.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3551\n",
      "INFO:tensorflow:loss = 0.0073959357, step = 25201 (5.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3001\n",
      "INFO:tensorflow:loss = 0.0062866844, step = 25301 (5.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3121\n",
      "INFO:tensorflow:loss = 0.010141318, step = 25401 (5.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.357\n",
      "INFO:tensorflow:loss = 0.041100547, step = 25501 (5.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2797\n",
      "INFO:tensorflow:loss = 0.038667116, step = 25601 (5.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1793\n",
      "INFO:tensorflow:loss = 0.025579175, step = 25701 (5.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3783\n",
      "INFO:tensorflow:loss = 0.007798381, step = 25801 (5.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3247\n",
      "INFO:tensorflow:loss = 0.008342242, step = 25901 (5.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3099\n",
      "INFO:tensorflow:loss = 0.013545141, step = 26001 (5.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8948\n",
      "INFO:tensorflow:loss = 0.02145781, step = 26101 (5.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1684\n",
      "INFO:tensorflow:loss = 0.015735215, step = 26201 (5.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0782\n",
      "INFO:tensorflow:loss = 0.021732554, step = 26301 (5.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3543\n",
      "INFO:tensorflow:loss = 0.02086195, step = 26401 (5.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9716\n",
      "INFO:tensorflow:loss = 0.01656993, step = 26501 (5.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3781\n",
      "INFO:tensorflow:loss = 0.01724192, step = 26601 (5.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5484\n",
      "INFO:tensorflow:loss = 0.028060362, step = 26701 (5.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.875\n",
      "INFO:tensorflow:loss = 0.01491324, step = 26801 (5.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2326\n",
      "INFO:tensorflow:loss = 0.02506472, step = 26901 (5.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.262\n",
      "INFO:tensorflow:loss = 0.020181911, step = 27001 (5.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.9821\n",
      "INFO:tensorflow:loss = 0.02561009, step = 27101 (5.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7832\n",
      "INFO:tensorflow:loss = 0.0046597808, step = 27201 (5.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8916\n",
      "INFO:tensorflow:loss = 0.017946796, step = 27301 (5.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1761\n",
      "INFO:tensorflow:loss = 0.008982699, step = 27401 (5.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3097\n",
      "INFO:tensorflow:loss = 0.07891423, step = 27501 (5.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2991\n",
      "INFO:tensorflow:loss = 0.02665858, step = 27601 (5.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.237\n",
      "INFO:tensorflow:loss = 0.01384655, step = 27701 (5.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1198\n",
      "INFO:tensorflow:loss = 0.01461084, step = 27801 (5.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7713\n",
      "INFO:tensorflow:loss = 0.048165575, step = 27901 (5.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4407\n",
      "INFO:tensorflow:loss = 0.02300835, step = 28001 (5.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5851\n",
      "INFO:tensorflow:loss = 0.022868361, step = 28101 (5.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7067\n",
      "INFO:tensorflow:loss = 0.038902692, step = 28201 (5.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2056\n",
      "INFO:tensorflow:loss = 0.08173325, step = 28301 (5.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2937\n",
      "INFO:tensorflow:loss = 0.07137242, step = 28401 (5.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2904\n",
      "INFO:tensorflow:loss = 0.02687272, step = 28501 (5.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3106\n",
      "INFO:tensorflow:loss = 0.018606458, step = 28601 (5.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3581\n",
      "INFO:tensorflow:loss = 0.0077152587, step = 28701 (5.166 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 19.3045\n",
      "INFO:tensorflow:loss = 0.011690335, step = 28801 (5.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2274\n",
      "INFO:tensorflow:loss = 0.043803737, step = 28901 (5.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4905\n",
      "INFO:tensorflow:loss = 0.01736525, step = 29001 (5.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8974\n",
      "INFO:tensorflow:loss = 0.038974263, step = 29101 (5.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.1782\n",
      "INFO:tensorflow:loss = 0.04259716, step = 29201 (5.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.312\n",
      "INFO:tensorflow:loss = 0.03443233, step = 29301 (5.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4032\n",
      "INFO:tensorflow:loss = 0.04709986, step = 29401 (5.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.3495\n",
      "INFO:tensorflow:loss = 0.0036865347, step = 29501 (5.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.9277\n",
      "INFO:tensorflow:loss = 0.049088333, step = 29601 (5.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.8688\n",
      "INFO:tensorflow:loss = 0.01912629, step = 29701 (5.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.9852\n",
      "INFO:tensorflow:loss = 0.018844558, step = 29801 (5.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.2525\n",
      "INFO:tensorflow:loss = 0.017854763, step = 29901 (5.194 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into ./udf_log/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.05276195.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fe789c46d30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn,steps=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64e9e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"image\":mnist.test.images},\n",
    "    y=mnist.test.labels.astype(np.int32),\n",
    "    num_epochs=1,\n",
    "    batch_size=128,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d138a785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78b90b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78b90b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78b90b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78b90b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78b90b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe78b90b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78b90b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe78b90b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe77a38fdd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe77a38fdd8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe77a38fdd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe77a38fdd8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78b90b160>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78b90b160>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe78b90b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe78b90b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78b90b160>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78b90b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe78b90b160>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2022-06-17T01:58:06Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /Users/fytang/workSpace/miniconda3/envs/tf114/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./udf_log/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2022-06-17-01:58:07\n",
      "INFO:tensorflow:Saving dict for global step 30000: global_step = 30000, loss = 0.029794343, my_metric = 0.9904\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 30000: ./udf_log/model.ckpt-30000\n"
     ]
    }
   ],
   "source": [
    "test_result = estimator.evaluate(input_fn=test_input_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2cb9460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test acc: 99.04 %\n"
     ]
    }
   ],
   "source": [
    "acc_score = test_result[\"my_metric\"]\n",
    "print(\"\\nTest acc: %g %%\" % (acc_score*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf80e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"image\":mnist.test.images[:20]},\n",
    "    num_epochs=1,\n",
    "    batch_size=128,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6446966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe789bbd320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe789bbd320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe789bbd320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe789bbd320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe789bbd320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fe789bbd320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe789bbd320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fe789bbd320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe7777174a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe7777174a8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe7777174a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe7777174a8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe789bbd320>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe789bbd320>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe789bbd320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fe789bbd320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe789bbd320>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe789bbd320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fe789bbd320>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./udf_log/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction 1: 7\n",
      "Prediction 2: 2\n",
      "Prediction 3: 1\n",
      "Prediction 4: 0\n",
      "Prediction 5: 4\n",
      "Prediction 6: 1\n",
      "Prediction 7: 4\n",
      "Prediction 8: 9\n",
      "Prediction 9: 5\n",
      "Prediction 10: 9\n",
      "Prediction 11: 0\n",
      "Prediction 12: 6\n",
      "Prediction 13: 9\n",
      "Prediction 14: 0\n",
      "Prediction 15: 1\n",
      "Prediction 16: 5\n",
      "Prediction 17: 9\n",
      "Prediction 18: 7\n",
      "Prediction 19: 3\n",
      "Prediction 20: 4\n"
     ]
    }
   ],
   "source": [
    "predictions = estimator.predict(input_fn =predict_input_fn )\n",
    "for i,p in enumerate(predictions):\n",
    "    print(\"Prediction %s: %s\" % (i+1,p[\"result\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1623f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
